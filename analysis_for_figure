import os
import sys
import time
import pickle
import warnings
import scipy.stats
import numpy as np
import pandas as pd
import caiman as cm
import seaborn as sns
import holoviews as hv
import matplotlib.pyplot as plt
from scipy.stats import ttest_ind
from matplotlib.patches import Rectangle
from sklearn.linear_model import LinearRegression
from scipy.ndimage.measurements import center_of_mass
from caiman.source_extraction.cnmf import cnmf as cnmf
from caiman.source_extraction.cnmf import params as params
with warnings.catch_warnings():
    warnings.filterwarnings("ignore",category=FutureWarning)
    warnings.filterwarnings("ignore",category=DeprecationWarning)
    warnings.filterwarnings("ignore",category=FutureWarning)
    import utilsss as ut
hv.extension('matplotlib')

sys.path.insert(1, '/home/pedro/Work/Hippocampus/code')
import to_Pedro as sut


data_path = '/media/pedro/DataTraveler/DetectionTest_2020Mar09'
data_name,median_projection,fnames,fname_new,results_caiman_path,boxes_path = ut.get_files_names(data_path)
## params
fr = 3.025                    # imaging rate in frames per second (data obtained from file ....)
decay_time = 0.65           # length of a typical transient in seconds (this is the value given by Marco Brondi, which is different from the one in the original notebook)

# motion correction parameters
strides = (48, 48)          # start a new patch for pw-rigid motion correction every x pixels
overlaps = (24, 24)         # overlap between patches (size of patch strides+overlaps)
max_shifts = (6,6)          # maximum allowed rigid shifts (in pixels)
max_deviation_rigid = 3     # maximum shifts deviation allowed for patch with respect to rigid shifts
pw_rigid = True             # flag for performing non-rigid motion correction

# parameters for source extraction and deconvolution
p = 0                       # order of the autoregressive system
gnb = 2                     # number of global background components
merge_thr = 1#0.85            # merging threshold, max correlation allowed
rf = None#24                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50
stride_cnmf = 15            # amount of overlap between the patches in pixels
K = 4                       # number of components per patch
gSig = (8,8)                # expected half size of neurons in pixels
method_init = 'greedy_roi'  # initialization method (if analyzing dendritic data using 'sparse_nmf')
ssub = 1                    # spatial subsampling during initialization
tsub = 1                    # temporal subsampling during intialization

# parameters for component evaluation
min_SNR = 2.0               # signal to noise ratio for accepting a component
rval_thr = 0.85             # space correlation threshold for accepting a component
cnn_thr = 0.99              # threshold for CNN based classifier
cnn_lowest = 0.1            # neurons with cnn probability lower than this value are rejected

opts_dict = {'fnames': fnames,
'fr': fr,
'decay_time': decay_time,
'strides': strides,
'overlaps': overlaps,
'max_shifts': max_shifts,
'max_deviation_rigid': max_deviation_rigid,
'pw_rigid': pw_rigid,
'p': p,
'nb': gnb,
'rf': rf,
'K': K,
'stride': stride_cnmf,
'method_init': method_init,
'rolling_sum': True,
'only_init': False,
'gSig': gSig,
'ssub': ssub,
'tsub': tsub,
'merge_thr': merge_thr,
'min_SNR': min_SNR,
'rval_thr': rval_thr,
'use_cnn': True,
'min_cnn_thr': cnn_thr,
'cnn_lowest': cnn_lowest}

opts = params.CNMFParams(params_dict=opts_dict)

# data preparation
ut.caiman_motion_correct(fnames,opts)

# run AGOnIA
if not boxes_path:
    ## detect with AGOnIA
    ut.agonia_detect(data_path,data_name,median_projection,multiplier=2.3)

# run seeded-CaImAn
agonia_th = .2
ut.seeded_Caiman_wAgonia(data_path,opts,agonia_th=agonia_th)
data_name,median_projection,fnames,fname_new,results_caiman_path,boxes_path = ut.get_files_names(data_path)
seeded = cnmf.load_CNMF(results_caiman_path)
seeded.estimates.nb_view_components(img=median_projection,denoised_color='red')

# run CaImAn
## change necesary parameters for not-seeded to work
opts_dict['only_init']=True
opts_dict['rf'] = 24
opts = params.CNMFParams(params_dict=opts_dict)

cnm,cnm2 = ut.run_caiman_pipeline(data_path,opts,refit=True,component_evaluation=True,fr=fr,rf=rf,decay_time=decay_time)
cnm.estimates.nb_view_components(img=median_projection, denoised_color='red')

# correlations
pepe =seeded.estimates.f.T[:,0]
np.corrcoef([pepe,neuropil_trace])[1,0]

## substract neuropil out of the mean of the boxes
denoised_traces, neuropil_trace = ut.substract_neuropil(data_path,agonia_th=agonia_th,neuropil_pctl=100,signal_pctl=80)

## calcular las correlaciones entre las medias de la box y los factores de caiman, usando el criterio de actividad de caiman
corr_comp, idx_active, boxes_traces = ut.trace_correlation(data_path,
agonia_th=agonia_th,select_cells=False,plot_results=False)

corrs_comp_denoised, idx_active, boxes_traces_denoised = ut.trace_correlation(data_path,
agonia_th=agonia_th,select_cells=False,plot_results=False,denoise=True)

plt.boxplot(corrs_comp_denoised)
corr_boxes = np.corrcoef(boxes_traces)
corr_caiman = np.corrcoef(seeded.estimates.C)
#corrs_comp_denoised = np.empty((denoised_traces.shape[0],denoised_traces.shape[0]))
#for i,box in enumerate(denoised_traces):
#    for j,c in enumerate(seeded.estimates.C):
#        corrs_comp_denoised[i,j] = np.corrcoef([box,c])[1,0]
corr_denoised = np.corrcoef(denoised_traces)

plt.figure(figsize=(30,10))
plt.subplot(131)
plt.title('Mean of boxes',fontsize=30)
plt.tick_params(labelsize=20)
plt.imshow(corr_boxes)
plt.subplot(132)
plt.title('Caiman denoised',fontsize=30)
plt.tick_params(labelsize=20)
plt.imshow(corr_caiman)
plt.subplot(133)
plt.title('Neuropil substracted',fontsize=30)
plt.tick_params(labelsize=20)
plt.imshow(corr_denoised)
#plt.subplot(134)
#plt.title('Manual vs CaImAn denoising')
#plt.imshow(corrs_comp_denoised)
plt.savefig(os.path.join(data_path,'correlation_matrices_weighted_neuropil'),format='pdf')
plt.show()
fig,ax = plt.subplots(figsize=(5,5))
plt.title('MedianVsCaiman Correlations',fontsize=15)
plt.boxplot([corr_comp,corrs_comp_denoised])
ax.set_xticklabels(['median','neuropil_subtracted'])
plt.ylim([0,1])
#plt.savefig(os.path.join(data_path,'correlation_median_or_denoised_weightedvsCaiman'),format='pdf')
plt.show()
ttest_ind(corr_comp,corrs_comp_denoised,equal_var=False)

#values1, base1 = np.histogram(np.diag(corrs_comp_denoised),bins=20)
values1, base1 = np.histogram(corrs_comp_denoised,bins=20)
cumulative_denoised = np.cumsum(values1)
values, base = np.histogram(corr_comp,bins=20)
cumulative = np.cumsum(values)
plt.plot(base1[:-1], cumulative_denoised, c='blue')
plt.plot(base[:-1], cumulative, c='green')

#local vs global noise correlations
local_global_corr = ut.localvsglobal_neuropil(data_path,.2)
plt.boxplot(local_global_corr)
plt.ylim([0,1])


clust_boxes = sns.clustermap(corr_boxes, method='average', metric='euclidean', figsize=(20,20), cmap=plt.cm.viridis, vmin=-1, vmax=1)
plt.savefig(os.path.join(data_path,'Dendrogram_meanboxes'),format='pdf')


clust_caiman = sns.clustermap(corr_caiman, method='average', metric='euclidean', figsize=(20,20), cmap=plt.cm.viridis, vmin=-1, vmax=1)
plt.savefig(os.path.join(data_path,'Dendrogram_caimanfactors'),format='pdf')


clust_caiman.dendrogram_row.dendrogram['leaves'][76]

clust_denoised = sns.clustermap(corr_denoised, method='average', metric='euclidean', figsize=(20,20), cmap=plt.cm.viridis, vmin=-1, vmax=1)
plt.savefig(os.path.join(data_path,'Dendrogram_meanboxes_denoised'),format='pdf')


# numer of mergings

# performance

#usar pca para ver si esta el neuropilo y ver los pesos sobre cada neurona.
stn = np.zeros(seeded.estimates.C.shape[0])
#for trace in seeded.estimates.C:
trace = seeded.estimates.C[9]
stn = np.array([(max(trace)-trace.mean())/np.std(trace[trace<np.std(trace)]) for trace in seeded.estimates.C])

stnr = ut.signal_to_noise(data_path,agonia_th)




















#
